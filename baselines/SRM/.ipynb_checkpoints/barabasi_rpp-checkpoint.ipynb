{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from srm.db_manager import connect_to_db, execute_sql\n",
    "import time\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def param_estimate(t_train, T):\n",
    "    \"\"\" For accurate calculation, use the last timestamp from t_train as T and the rest shall be passed as \n",
    "    commandline arguments to estimate parameters\n",
    "    \"\"\"\n",
    "    t_args = \"\\t\".join(str(x) for x in t_train[:-1])\n",
    "    #print command_arg\n",
    "    res = !./rpp  $T $t_args\n",
    "    #print res\n",
    "    l, mu, sigma = (float(x) for x in \"\".join(res).split('\\t'))\n",
    "    #print l, mu, sigma\n",
    "    return l, mu, sigma\n",
    "\n",
    "def predict(l, mu, sigma, T, nd, tp) :\n",
    "    m = 10 # Prior bilief. Make sure m_m in mic_model.cpp has the same value\n",
    "    f_tp = norm.cdf((math.log(tp) - mu)/sigma)\n",
    "    norm.cdf(f_tp)    \n",
    "    f_T = norm.cdf((math.log(T) - mu)/sigma)\n",
    "    norm.cdf(f_T)\n",
    "    cn = (m + nd)*math.exp((f_tp - f_T)*l) - m\n",
    "    #print \"Predicted\", int(math.ceil(cn))\n",
    "    #print cn\n",
    "    try:\n",
    "        te = int(math.ceil(cn))\n",
    "        return te\n",
    "    except:\n",
    "        #print cn\n",
    "        return -1\n",
    "    \n",
    "def mape(ta, tp):\n",
    "    \"\"\"Calculated MAPE for actual values ta and predicted values tp\n",
    "    \"\"\"\n",
    "    diff = 0\n",
    "    n = len(ta)\n",
    "    for i in range(n):\n",
    "        diff+= abs(ta[i]-tp[i])/float(ta[i])\n",
    "    return diff/n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db_name, table = \"srm\", \"BigBillionDay\"\n",
    "cursor_mysql, conn = connect_to_db(\"localhost\", \"root\", \"root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the graph MAPE vs time after training timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parent_tweets = [row[0] for row in execute_sql(\"select parent_id_str from srm.BigBillionDay where parent_id_str in \\\n",
    "(SELECT  distinct id_str from srm.BigBillionDay) \\\n",
    " group by parent_id_str having count(*) >50 order by count(*) desc;\")]\n",
    "#print parent_tweets\n",
    "prediction_dict = defaultdict(list) #{tweetid:(time after training, real retweet#, predicted retweet#)}\n",
    "\n",
    "for parent_id in parent_tweets :\n",
    "    #print \"Parent ID\", parent_id\n",
    "    retweet_times = [row[0] for row in execute_sql(\"select created_at from srm.BigBillionDay where parent_id_str \\\n",
    "                                                            =%s order by created_at\", parent_id)]\n",
    "    parent_created_time = [row[0] for row in execute_sql(\"select created_at from srm.BigBillionDay where id_str \\\n",
    "                                                            =%s\", parent_id)]\n",
    "    created_times = parent_created_time #Stores time at which the tweet and retweets are created\n",
    "    created_times.extend(retweet_times)\n",
    "    t_original = list()\n",
    "    for ts in created_times : \n",
    "        t_original.append(int(time.mktime(ts.timetuple())-time.mktime(created_times[0].timetuple())))\n",
    "    \n",
    "    #To avoid errors in calculation, as suggested in the paper, we add a constant 1 to the time momemnts\n",
    "    t_original = [x+1 for x in t_original]\n",
    "    \n",
    "    #Training \n",
    "    split_limit = int(len(t_original)*.7) #70% for training 30 % for testing\n",
    "    t_train, t_test = t_original[0:split_limit], t_original[split_limit:]\n",
    "    T = t_train[-1]\n",
    "    l, mu, sigma = param_estimate(t_train, T)\n",
    "    \n",
    "    #Calculation of MAPE\n",
    "    nd = len(t_train[:-1])\n",
    "    \n",
    "    for tp in t_test:\n",
    "        te = predict(l, mu, sigma, T, nd, tp)\n",
    "        if te == -1 : \n",
    "            continue\n",
    "        #print \"Real\", t_original.index(tp)+1\n",
    "        if not prediction_dict.has_key(parent_id):\n",
    "            prediction_dict[parent_id] = [(tp-T, t_original.index(tp)+1, te)]\n",
    "        else :\n",
    "            prediction_dict[parent_id].append((tp-T, t_original.index(tp)+1, te))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(14, 187, 186), (213, 188, 187), (694, 189, 191), (1482, 190, 196), (1502, 191, 197), (1521, 192, 197), (1551, 193, 197), (1888, 194, 200), (2246, 195, 202), (2393, 196, 203), (3670, 197, 213), (4024, 198, 216), (4080, 199, 217), (4361, 200, 219), (4582, 201, 221), (4708, 202, 222), (4902, 203, 223), (5733, 204, 230), (6653, 205, 238), (6927, 206, 241), (7031, 207, 242), (7294, 208, 244), (7620, 209, 247), (7631, 210, 247), (7675, 211, 247), (7824, 212, 249), (7834, 213, 249), (7914, 214, 249), (8407, 215, 254), (9307, 216, 262), (9798, 217, 267), (10181, 218, 270), (10979, 219, 278), (11093, 220, 279), (11740, 221, 285), (11929, 222, 287), (12579, 223, 293), (12771, 224, 295), (13481, 225, 303), (13558, 226, 303), (13561, 227, 303), (14152, 228, 309), (14343, 229, 311), (14520, 230, 313), (14570, 231, 314), (15095, 232, 319), (15174, 233, 320), (15266, 234, 321), (15734, 235, 326), (16285, 236, 332), (16528, 237, 335), (17669, 238, 347), (18273, 239, 354), (18474, 240, 357), (18932, 241, 362), (19258, 242, 366), (19718, 243, 371), (19850, 244, 373), (21838, 245, 397), (22416, 246, 404), (22491, 247, 405), (22647, 248, 407), (25269, 249, 441), (28049, 250, 479), (29227, 251, 496), (29537, 252, 501), (32087, 253, 539), (34364, 254, 576), (34810, 255, 583), (63894, 256, 1226), (64369, 257, 1240), (68572, 258, 1365), (69432, 259, 1392), (78533, 260, 1702), (83812, 261, 1905), (83917, 262, 1909), (94265, 263, 2360), (111303, 264, 3275), (116368, 265, 3595), (143550, 266, 5742), (146802, 267, 6054)]\n",
      "518837102096564224\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "print prediction_dict[prediction_dict.keys()[2]]\n",
    "print prediction_dict.keys()[2]\n",
    "print len(prediction_dict[prediction_dict.keys()[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "8.15550603756e+51\n"
     ]
    }
   ],
   "source": [
    "xp, xe = list(), list()\n",
    "for k in prediction_dict.keys():\n",
    "    #print prediction_dict[k]\n",
    "    xp.extend([x[1] for x in prediction_dict[k]])\n",
    "    xe.extend([x[2] for x in prediction_dict[k]])\n",
    "print len(xp) == len(xe)\n",
    "print mape(xp, xe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
